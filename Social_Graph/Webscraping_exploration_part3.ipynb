{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In parts one and two - we extracted names from photo captions and parsed them\n",
    "\n",
    "# Here, in part Three - we create the social graph \n",
    "\n",
    "\n",
    "# This project will scrape a New York Social Diary website and identify divs with\n",
    "# photos and photo captions. Parsing the captions will yield a social network graph \n",
    "# of the New York Social Elite.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "matplotlib.rcParams['savefig.dpi'] = 2 * matplotlib.rcParams['savefig.dpi']\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib2\n",
    "import re\n",
    "from xml.sax.saxutils import escape\n",
    "from HTMLParser import HTMLParser\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import dill\n",
    "import time\n",
    "import itertools\n",
    "from itertools import chain\n",
    "import csv\n",
    "#import nltk\n",
    "#from nltk.tag import pos_tag\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in the list of names\n",
    "\n",
    "list_of_words2 = pickle.load(open('all_names_for_graph_full.pickle', 'rb'))\n",
    "\n",
    "# here we can also open the smaller pickle file\n",
    "\n",
    "#list_of_words2 = pickle.load(open('NOV16_az_captions_parsed_small.pickle', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_combo = []\n",
    "for line in list_of_words2:\n",
    " \n",
    "    try:\n",
    "        if str(line) == str(['']):\n",
    "            pass #print len(line) #pass\n",
    "        else:\n",
    "            if len(line) == 1:\n",
    "                pass\n",
    "            else:\n",
    "                #print \"yes\", line\n",
    "                k=(list(itertools.combinations(line,2)))    #creating all possible two tuple combinations \n",
    "                                                            #of names that are in a picture \n",
    "                data_combo.append(k)\n",
    "                # added a statement not to append if one name only\n",
    "                # think I did this twice then! data vs list_of_words\n",
    "    \n",
    "    except:   \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Les Lieberman', 'Isabel Kallman')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_combo[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67685"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_combo) # now excludes single names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create graph\n",
    "import operator\n",
    "eM = nx.MultiGraph()\n",
    "Gee = nx.Graph()\n",
    "\n",
    "\n",
    "for line in data_combo:\n",
    "    for node in line:\n",
    "        try:                  \n",
    "                eM.add_node(node[0])\n",
    "                eM.add_node(node[1])\n",
    "                eM.add_edge(node[0], node[1], weight = 1)\n",
    "                \n",
    "        except Exception, e:\n",
    "            print str(e)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate best friends - or the edges with highest weights\n",
    "w=0\n",
    "name1=[]\n",
    "name2=[]\n",
    "wt=[]\n",
    "for u,v,data in eM.edges_iter(data=True):\n",
    "    w = data['weight']\n",
    "    if Gee.has_edge(u,v):\n",
    "        Gee[u][v]['weight'] += w\n",
    "    else:\n",
    "        Gee.add_edge(u, v, weight=w)\n",
    "        \n",
    "for line in Gee.edges(data=True):\n",
    "    if (str(line[0])!='') and (str(line[0])!=''):        \n",
    "        name1.append(str(line[0]))\n",
    "        name2.append(str(line[1]))\n",
    "        k=line[2].get('weight')\n",
    "        wt.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edges_mapped=zip(zip(name1,name2),wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Christie Fraser', 'Liz Celeste'), 1),\n",
       " (('Dennis Serras', 'Marlo Bakst'), 1),\n",
       " (('Dennis Serras', 'Mikhail Baryshnikov'), 1),\n",
       " (('Dennis Serras', 'Tara Nasta'), 1),\n",
       " (('Ryan Swardstrom', 'Tom Dolby'), 1),\n",
       " (('Ryan Swardstrom', 'Peter Spears'), 1),\n",
       " (('Lynne Cherry', 'Olivia Bolar'), 1),\n",
       " (('Lynne Cherry', 'Shonda Hornbeck'), 1),\n",
       " (('Leslie Kirschenbaum', 'Elise Zealand'), 1),\n",
       " (('Samuel Barnett', 'Jano Herbosch'), 1)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_mapped[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edges_sorted=[]\n",
    "edges_sorted = sorted(edges_mapped,key=lambda x:(x[1]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_100edges = edges_sorted[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Bonnie Comley', 'Stewart Lane'), 75),\n",
       " (('Roric Tobin', 'Geoffrey Bradfield'), 67),\n",
       " (('Andrew Saffir', 'Daniel Benedict'), 66),\n",
       " (('Jay Diamond', 'Alexandra Lebenthal'), 51),\n",
       " (('Sessa Von Richthofen', 'Richard Johnson'), 44),\n",
       " (('Elizabeth Stribling', 'Guy Robinson'), 38),\n",
       " (('Deborah Norville', 'Karl Wellner'), 35),\n",
       " (('Wilbur Ross', 'Hilary Geary Ross'), 34),\n",
       " (('Fernanda Kellogg', 'Kirk Henckels'), 32),\n",
       " (('Douglas Hannant', 'Frederick Anderson'), 31)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_100edges[0:10] # best friends - edges with highest weights - top 100 for the grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"best_friends_edges_and_weights_full.csv\", \"wb\") as fin:\n",
    "    writer = csv.writer(fin)\n",
    "    writer.writerows(edges_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Jean Shafiroff', 603), ('Mark Gilbertson', 485), ('Gillian Miniter', 421), ('Geoffrey Bradfield', 376), ('Alexandra Lebenthal', 356), ('Gala Co', 320), ('Andrew Saffir', 293), ('Debbie Bancroft', 292), ('Patrick Mc', 284), ('Somers Farkas', 284), ('Sharon Bush', 281), ('Yaz Hernandez', 268), ('Alina Cho', 257), ('Michael Bloomberg', 255), ('Muffie Potter Aston', 250), ('Bonnie Comley', 236), ('Lydia Fenet', 234), ('Eleanora Kennedy', 233), ('Kamie Lightburn', 233)]\n"
     ]
    }
   ],
   "source": [
    "# calcualte the most popular people - top N people and their degree\n",
    "nods=[]\n",
    "degs=[]\n",
    "for line in eM.nodes():\n",
    "    nods.append(str(line))\n",
    "    degs.append(eM.degree(line))\n",
    "ans=zip(nods,degs)\n",
    "\n",
    "final1 = ans\n",
    "final1 = filter(None, final1)\n",
    "\n",
    "popnames=[]\n",
    "mostpop=[]\n",
    "for line in final1:        \n",
    "    popnames.append(line)\n",
    "        \n",
    "mostpop= sorted(popnames,key=lambda x:(x[1]), reverse=True)\n",
    "print mostpop[1:20]\n",
    "\n",
    "with open(\"most_popular_degree_full.csv\", \"wb\") as fin:\n",
    "    writer = csv.writer(fin)\n",
    "    writer.writerows(mostpop)\n",
    "    \n",
    "# remove the cases with ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# top 100 for the grader answer\n",
    "top100=[]\n",
    "top100 = sorted(popnames,key=lambda x:(x[1]), reverse=True)[:100]\n",
    "#print top100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Jean Shafiroff', 0.0006864700052017189), ('Mark Gilbertson', 0.0005417128682241713), ('Gillian Miniter', 0.00044507759230796146), ('Gala Co', 0.00042745248616805453), ('Geoffrey Bradfield', 0.0004116957319992117), ('Patrick Mc', 0.00040923815572880645), ('Alexandra Lebenthal', 0.00037115355512113725), ('Andrew Saffir', 0.0003613528617321991), ('Sharon Bush', 0.000322713985758053)]\n"
     ]
    }
   ],
   "source": [
    "# calculate page rank\n",
    "# Use 0.85 as the damping parameter so that there is a 15% chance of jumping to\n",
    "# another vertex at random. This is the nx default\n",
    "\n",
    "pgrank=[]\n",
    "pgsorted=[]\n",
    "pgrank=nx.pagerank(Gee)\n",
    "pgsorted = sorted(pgrank.items(), key=operator.itemgetter(1), reverse=True)\n",
    "print pgsorted[1:10]\n",
    "with open(\"pagerank_full.csv\", \"wb\") as final:\n",
    "    writer = csv.writer(final)\n",
    "    writer.writerows(pgsorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the graph to a graph file so we can operate on it with Gephi and other viz tools in a diff. notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nx.write_gexf(Gee,'Gee.gexf') # 20MB file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# but also write out a gml graph that can be read in by part 4.\n",
    "nx.write_gml(Gee, \"Gee_full.gml.gz\")\n",
    "nx.write_graphml(Gee, \"Gee.graphml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
