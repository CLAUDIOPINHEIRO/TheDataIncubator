{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  This project will scrape a New York Social Diary website http://www.newyorksocialdiary.com\n",
    "#  - identify divs with photos and photo captions\n",
    "#  - parsing the captions and yield a social network graph of the New York Social Elite.\n",
    "\n",
    "#  The graph visulization will be done with Tableau or networkx -> graph_tool or gephi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "matplotlib.rcParams['savefig.dpi'] = 2 * matplotlib.rcParams['savefig.dpi']\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib2\n",
    "import re\n",
    "from xml.sax.saxutils import escape\n",
    "from HTMLParser import HTMLParser\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import dill\n",
    "import time\n",
    "import itertools\n",
    "from itertools import chain\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyHTMLParser_test(HTMLParser):\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        print \"Encountered a start tag:\", tag\n",
    "    def handle_endtag(self, tag):\n",
    "        #return\n",
    "        print \"Encountered an end tag :\", tag\n",
    "    def handle_data(self, data):\n",
    "        #return\n",
    "        print \"Encountered some data  :\", data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a subclass and override the handler methods\n",
    "class MyHTMLParser(HTMLParser):\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        if tag == \"a\":\n",
    "            for name, value in attrs:\n",
    "                print value\n",
    "    def handle_endtag(self, tag):\n",
    "        return\n",
    "    def handle_data(self, data):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# redefine parser\n",
    "class MyHTMLParser_2(HTMLParser):\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        if tag == \"a\":\n",
    "            for name, value in attrs:\n",
    "                self.data = value\n",
    "    def handle_endtag(self, tag):\n",
    "        return\n",
    "    def handle_data(self, data):\n",
    "        self.data = self.data\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here we go - example album is \n",
    "# http://www.newyorksocialdiary.com/party-pictures/2016/celebrating-the-neighborhood\n",
    "# The archive is a number of pages\n",
    "# 0th http://www.newyorksocialdiary.com/party-pictures\n",
    "# 1st http://www.newyorksocialdiary.com/party-pictures?page=1\n",
    "# 28th and last is http://www.newyorksocialdiary.com/party-pictures?page=27\n",
    "# so there are 28 pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = \"http://www.newyorksocialdiary.com/party-pictures\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.newyorksocialdiary.com/party-pictures?page=0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'<!DOCTYPE html>\\n  <!--[if IEMobile 7]><html class=\"no-js ie iem7\" lang=\"en\" dir=\"ltr\"><![endif]-->\\n  <!--[if lte IE 6]><html class=\"no-js ie lt-ie9 lt-ie8 lt-ie7\" lang=\"en\" dir=\"ltr\"><![endif]-->\\n  <!--[if (IE 7)&(!IEMobile)]><html class=\"no-js ie lt-ie9 lt-ie8\" lang=\"en\" dir=\"ltr\"><![endif]-->\\n  <!--[if IE 8]><html class=\"no-js ie lt-ie9\" lang=\"en\" dir=\"ltr\"><![endif]-->\\n  <!--[if (gte IE 9)|(gt IEMobile 7)]><html class=\"no-js ie\" lang=\"en\" dir=\"ltr\" prefix=\"fb: http://ogp.me/ns/fb# og: http://ogp.me/ns# article: http://ogp.me/ns/article# book: http://ogp.me/ns/book# profile: http://ogp.me/ns/profile# video: http://ogp.me/ns/video# product: http://ogp.me/ns/product#\"><![endif]-->\\n  <!--[if !IE]><!--><html class=\"no-js\" lang=\"en\" dir=\"ltr\" prefix=\"fb: http://ogp.me/ns/fb# og: http://ogp.me/ns# article: http://ogp.me/ns/article# book: http://ogp.me/ns/book# profile: http://ogp.me/ns/profile# video: http://ogp.me/ns/video# product: http://ogp.me/ns/product#\"><!--<![endif]-->\\n<head>\\n  <ti...'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(url, params={\"page\": 0})\n",
    "print response.url\n",
    "response.text[:1000] + \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# there is page zero remember \n",
    "# http://www.newyorksocialdiary.com/party-pictures?page=0\n",
    "# page 29 does not exist currently byt 28 does and looks to be empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(urllib2.urlopen(response.url), \"lxml\") # lxml gets rid of the parser choice warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parent_div = soup.find('div', attrs={'class': 'view-content'}) #Find (at most) *one*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parent_div # too large for Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# img_divs = parent_div.find_all('div', attrs={'class':'technology'})  #Find *all* # fails returns []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_divs = parent_div.find_all('div', attrs={'class':'views-row'})  #Find *all*\n",
    "len(link_divs) # number of albums on page 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#link_divs # where we have href links with album names!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"views-row views-row-1 views-row-odd views-row-first\">\\n<span class=\"views-field views-field-title\"> <span class=\"field-content\"><a href=\"/party-pictures/2016/celebrating-the-neighborhood\">Celebrating the Neighborhood</a></span> </span>\\n<span class=\"views-field views-field-created\"> <span class=\"field-content\">Monday, November 14, 2016</span> </span> </div>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st album when I do this is in here - Celebrating the neighborhood Monday Nov 14th\n",
    "link_divs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to detect href links - I found MyHTMLParser()..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test call yields data now href value\n",
    "parser_tester = MyHTMLParser_test()\n",
    "parser = MyHTMLParser()\n",
    "parser_2 = MyHTMLParser_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encountered a start tag: p\n",
      "Encountered a start tag: a\n",
      "Encountered some data  : Example Link\n",
      "Encountered an end tag : a\n",
      "Encountered an end tag : p\n"
     ]
    }
   ],
   "source": [
    "parser_tester.feed('<p><a href=\"http://www.quackit.com/html/tutorial/html_links.cfm\">Example Link</a></p>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser_2.feed('<p><a href=\"http://www.quackit.com/html/tutorial/html_links.cfm\">Example Link</a></p>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://www.quackit.com/html/tutorial/html_links.cfm'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser_2.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.quackit.com/html/tutorial/html_links.cfm\n"
     ]
    }
   ],
   "source": [
    "# example of how simple parser can be\n",
    "parser.feed('<p><a href=\"http://www.quackit.com/html/tutorial/html_links.cfm\">Example Link</a></p>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/party-pictures/2016/summer-swan-song\n"
     ]
    }
   ],
   "source": [
    "parser.feed('<div class=\"views-row views-row-1 views-row-odd views-row-first\">\\n<span class=\"views-field views-field-title\"> <span class=\"field-content\"><a href=\"/party-pictures/2016/summer-swan-song\">Summer swan song</a></span> </span>\\n<span class=\"views-field views-field-created\"> <span class=\"field-content\">Tuesday, September 6, 2016</span> </span> </div>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parser_2.feed('<div class=\"views-row views-row-1 views-row-odd views-row-first\">\\n<span class=\"views-field views-field-title\"> <span class=\"field-content\"><a href=\"/party-pictures/2016/celebrating-the-neighborhood\">Celebrating the Neighborhood</a></span> </span>\\n<span class=\"views-field views-field-created\"> <span class=\"field-content\">Monday, November 14, 2016</span> </span> </div>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/party-pictures/2016/celebrating-the-neighborhood'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser_2.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "div_list = []\n",
    "for i in range(0,len(link_divs)):\n",
    "    div_list.append(str(link_divs[i]))        # div_list with album titles\n",
    "    #print link_divs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/party-pictures/2016/celebrating-the-neighborhood\n",
      "/party-pictures/2016/a-rarity-these-days\n",
      "/party-pictures/2016/fall-fetes\n",
      "/party-pictures/2016/distinguished-service\n",
      "/party-pictures/2016/the-arts\n",
      "/party-pictures/2016/arts-and-education\n",
      "/party-pictures/2016/trailblazers\n",
      "/party-pictures/2016/lighting-up-lives\n",
      "/party-pictures/2016/an-extra-boost\n",
      "/party-pictures/2016/when-museums-are-built\n",
      "/party-pictures/2016/fulfillment-of-agenda\n",
      "/party-pictures/2016/a-look-around-the-neighborhood\n",
      "/party-pictures/2016/new-york-after-dark\n",
      "/party-pictures/2016/fact-vs-fiction\n",
      "/party-pictures/2016/fall-fun\n",
      "/party-pictures/2016/lessons-learned\n",
      "/party-pictures/2016/championing-the-makers\n",
      "/party-pictures/2016/same-sky\n",
      "/party-pictures/2016/new-yorkers-for-children-celebrates-20\n",
      "/party-pictures/2016/artistry-of-fashion\n",
      "/party-pictures/2016/summer-swan-song\n",
      "/party-pictures/2016/the-grand-voyage\n",
      "/party-pictures/2016/classic-moments\n",
      "/party-pictures/2016/summer-fun-and-fashion\n",
      "/party-pictures/2016/the-7th-annual-apollo-in-the-hamptons\n",
      "/party-pictures/2016/animal-rescue-fund-of-the-hamptons-annual-bow-wow-meow-ball\n",
      "/party-pictures/2016/tireless-efforts\n",
      "/party-pictures/2016/ovarian-cancer-research-fund-alliances-19th-annual-super-saturday\n",
      "/party-pictures/2016/paddle-party-for-pink\n",
      "/party-pictures/2016/hope-and-valor\n",
      "/party-pictures/2016/the-watermill-centers-fada-house-of-madness-summer-benefit\n",
      "/party-pictures/2016/serious-moonlight\n",
      "/party-pictures/2016/walk-of-hope\n",
      "/party-pictures/2016/the-view-from-the-top\n",
      "/party-pictures/2016/what-you-might-have-missed\n",
      "/party-pictures/2016/empowering-women-and-awarding-men\n",
      "/party-pictures/2016/transforming-and-beautifying\n",
      "/party-pictures/2016/empowerment\n",
      "/party-pictures/2016/awards-and-accolades\n",
      "/party-pictures/2016/celebrating-fashion-fun-and-flora\n",
      "/party-pictures/2016/sliding-into-summer\n",
      "/party-pictures/2016/a-touch-of-gold\n",
      "/party-pictures/2016/pivotal-moments\n",
      "/party-pictures/2016/recipients-performers-and-well-wishers\n",
      "/party-pictures/2016/the-society-of-memorial-sloan-kettering-gray-matters-and-icmec\n",
      "/party-pictures/2016/dressed-for-the-occasion\n",
      "/party-pictures/2016/looking-for-answers\n",
      "/party-pictures/2016/anniversary-celebrations\n",
      "/party-pictures/2016/love-and-art\n",
      "/party-pictures/2016/friends-and-community-members\n",
      "There are 50 albums in total\n"
     ]
    }
   ],
   "source": [
    "# print all album names so far\n",
    "for i in range(0,len(div_list)):\n",
    "    parser.feed(div_list[i])\n",
    "\n",
    "print \"There are \"+str(i+1)+\" albums in total\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we loop over the pages to get all the albums on the site...\n",
    "# sub-select from a data range\n",
    "# extract all captions\n",
    "# extract captions with less than 250 characters - longer captions are not just names...\n",
    "# make a network graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "master_list = []\n",
    "for i in range(3,5): #28): # old project date range\n",
    "#for i in range(0,28): # very dirty getting rid of date stuff\n",
    "    response = requests.get(url, params={\"page\": i})\n",
    "    #wait time\n",
    "    #print response.url\n",
    "    soup = BeautifulSoup(urllib2.urlopen(response.url),\"lxml\")\n",
    "    parent_div = soup.find('div', attrs={'class': 'view-content'}) #Find (at most) *one*\n",
    "    link_divs = parent_div.find_all('div', attrs={'class':'views-row'})  #Find *all*\n",
    "    #print len(link_divs)\n",
    "    #print link_divs[0]\n",
    "    #break\n",
    "    new_list = []\n",
    "    for j in range(0,len(link_divs)):\n",
    "        new_list.append(str(link_divs[j]))\n",
    "        parser_2.feed(new_list[j])\n",
    "        #print parser_2.data\n",
    "        #break\n",
    "        master_list.append(parser_2.data)\n",
    "\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print len(master_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#master_list[:36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(master_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_list2014 = master_list[35:]\n",
    "len(new_list2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/party-pictures/2014/gala-guests'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_list2014[0] # we want to start with '/party-pictures/2014/gala-guests' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You know what this does, right?\n",
    "# It gets all the div data in one swoop\n",
    "\n",
    "def myhtmlcall(link):\n",
    "    url =  \"http://www.newyorksocialdiary.com\" + link\n",
    "    return requests.get(url).text\n",
    "    \n",
    "p = Pool(8)\n",
    "newobj  = p.map(myhtmlcall, new_list2014)\n",
    "\n",
    "\n",
    "# save to pickle\n",
    "with open(\"all_div_all_captions.pickle\", \"wb\") as file:\n",
    "    pickle.dump(newobj, file)\n",
    "    \n",
    "# read in as n = pickle.load(open('file.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'<!DOCTYPE html>\\n  <!--[if IEMobile 7]><html class=\"no-js ie iem7\" lang=\"en\" dir=\"ltr\"><![endif]-->\\n '"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only print this if len(new_list2014) < 100 or\n",
    "newobj[0][0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oldobj = pickle.load(open('all_div_all_captions.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'<!DOCTYPE html>\\n  <!--[if IEMobile 7]><html class=\"no-js ie iem7\" lang=\"en\" dir=\"ltr\"><![endif]-->\\n '"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oldobj[0][0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a subclass and override the handler methods\n",
    "class MyHTMLParser3(HTMLParser):\n",
    "    \n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        if tag == \"a\":\n",
    "            for name, value in attrs:\n",
    "                self.data = value # this overwrites the data aspect which is our captions\n",
    "                #print value\n",
    "    \n",
    "    def handle_endtag(self, tag):\n",
    "        return\n",
    "    \n",
    "    def handle_data(self, data):\n",
    "        self.data = data      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser2 = MyHTMLParser_2()\n",
    "parser3 = MyHTMLParser3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5631 5631 5631\n"
     ]
    }
   ],
   "source": [
    "caption_div = []\n",
    "caption_indx = []\n",
    "master_caps = []\n",
    "master_caps2 = []\n",
    "for i in range(0,len(newobj)):\n",
    "    soup = BeautifulSoup(newobj[i],\"lxml\")\n",
    "    # this is the crucial step - this is where you miss captions!\n",
    "    caption_divs_main = soup.find_all('font', attrs={'face': 'Verdana, Arial, Helvetica, sans-serif'}) #Find all* # 5385\n",
    "    ####caption_divs1 = soup.find_all('div', attrs={'class': 'photocaption'}) #Find all* # 73113\n",
    "    caption_divs2 = soup.find_all(\"div\", {'align': 'center', 'class': 'photocaption'}, text=True)\n",
    "    caption_divs3 = soup.find_all(\"td\", {'valign': 'top', 'class': 'photocaption'}, text=True)\n",
    "    caption_divs4 = soup.find_all(\"td\", {'valign': 'top', 'class': 'photocaption', 'style': 'background-color:#faf9ee'}, text=True)\n",
    "    ###caption_divs = soup.find_all(\"font\", {'size': 1, 'face': 'Verdana, Arial, Helvetica, sans-serif'}, text=True) #5301\n",
    "    caption_divs = caption_divs_main + caption_divs2 + caption_divs3 + caption_divs4\n",
    "    #  print caption_divs_main # useful for debugging\n",
    "    #  caption_divs = caption_divs_main\n",
    "    caption_indx.append(len(caption_divs))\n",
    "    for j in range(0,len(caption_divs)):\n",
    "        master_caps.append(caption_divs[j])\n",
    "        #print caption_divs[j]\n",
    "        parser3.feed(str(caption_divs[j]))\n",
    "        master_caps2.append(parser3.data)\n",
    "        #parser2.feed(str(caption_divs[j]))\n",
    "        #master_caps2.append(parser2.data)\n",
    "print len(master_caps), sum(caption_indx), len(master_caps2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div align=\"center\" class=\"photocaption\">The scene at   IDEAL School &amp; Academy\\u2019s  10th\\xa0Annual Gala.</div>,\n",
       " <div align=\"center\" class=\"photocaption\"> Les Lieberman, Barri Lieberman, Isabel Kallman, Trish Iervolino, and Ron Iervolino </div>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_caps[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Academy\\xe2\\x80\\x99s  10th\\xc2\\xa0Annual Gala.',\n",
       " ' Les Lieberman, Barri Lieberman, Isabel Kallman, Trish Iervolino, and Ron Iervolino ']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_caps2[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Congresswoman Carolyn Maloney and Manhattan Borough President Gale Brewer \n"
     ]
    }
   ],
   "source": [
    "print str(master_caps2[1345])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sum = 0\n",
    "list250char = []\n",
    "#print len(master_caps2[1345])\n",
    "for i in range(0,len(master_caps2)):\n",
    "    if len(str(master_caps2[i])) > 249: # was 250\n",
    "        pass\n",
    "        #print i, str(master_caps2[i])\n",
    "        #sum += 1\n",
    "    else:\n",
    "        list250char.append(master_caps2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Academy\\xe2\\x80\\x99s  10th\\xc2\\xa0Annual Gala.',\n",
       " ' Les Lieberman, Barri Lieberman, Isabel Kallman, Trish Iervolino, and Ron Iervolino ',\n",
       " ' Chuck Grodin ',\n",
       " ' Diana Rosario, Ali Sussman, Sarah Boll, Jen Zaleski, Alysse Brennan, and Lindsay Macbeth ',\n",
       " ' Kelly  and Tom Murro ',\n",
       " ' Udo Spreitzenbarth ',\n",
       " ' Ron Iervolino, Trish Iervolino, Russ Middleton, and Lisa Middleton ',\n",
       " ' Barbara Loughlin, Dr. Gerald Loughlin, and Debbie Gelston ',\n",
       " ' Julianne Michelle ',\n",
       " ' Heather Robinson, Kiwan Nichols, Jimmy Nichols, Melanie Carbone, and Nancy Brown ',\n",
       " ' Bill Mack and Les Lieberman ',\n",
       " ' Dr. David Lyden and Patricia Sorenson ',\n",
       " ' Jimmy Cayne, Vince Tese, and Pat Cayne ',\n",
       " ' Stuart Oran, Les Lieberman, and Hilary Oran ',\n",
       " ' Vince Tese and Chuck Grodin ',\n",
       " ' Dwight Gooden and Les Lieberman ',\n",
       " ' Dr. Amy Cunningham-Bussel, Ray Mirra, and Dr. Tyler Janovitz ',\n",
       " ' Dan Shedrick and Samara Heafitz ',\n",
       " ' Cass and Jason Adelman ',\n",
       " ' Bart Scott and Mark Laplander ']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list250char[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5614"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list250char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write out captions\n",
    "thefile = open('NOV16_az_captions.txt', 'w') # was test_az...\n",
    "for item in list250char:\n",
    "  thefile.write(\"%s\\n\" % item)\n",
    "\n",
    "# save to pickle\n",
    "with open(\"NOV16_az_captions.pickle\", \"wb\") as file:\n",
    "    pickle.dump(list250char, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In part 2 we extract names from captions\n",
    "# and make a social graph, calculate page rank etc\n",
    "# In part 3 we explore visualization tools for social graph networks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
